# íŒŒì¼ëª…: rag/app_demo.py
# ëª©ì :
#   - 03_search_demo.py ë™ì  ë¡œë“œ
#   - get_retriever() ìë™ í•´ì„
#   - [ìë™ ì¹´í…Œê³ ë¦¬] itemsì—ì„œ ì‹¤ì œ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ â†’ í”„ë¡œí† íƒ€ì…/ë³„ì¹­ ìë™ í•™ìŠµ
#   - ì¹´í…Œê³ ë¦¬ ì¸ì§€í˜• ê²€ìƒ‰(ì¬ì •ë ¬ + ì˜¤ë²„í˜ì¹˜ + ì¿¼ë¦¬ í™•ì¥)
#   - ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìŠ¤ì½”ì–´ ë³´ì • + ê°•ì œ ì¹´í…Œê³ ë¦¬ í•„í„°
#   - ì „/ì¤‘/í›„ í˜¼ì„  ë°©ì§€: í•µì‹¬ í‚¤ ë¹„êµ + ì•ˆì „ alias ë§¤ì¹­ + STOP_ALIASES
# ì‹¤í–‰: (.venv) streamlit run rag/app_demo.py

from __future__ import annotations

import sys
from pathlib import Path
import importlib.util
from typing import Any, Dict, List, Tuple

import re
import numpy as np
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) importlib ë¡œë”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def load_search_demo_module() -> Any:
    here = Path(__file__).resolve().parent
    module_path = here / "03_search_demo.py"
    if not module_path.exists():
        raise FileNotFoundError(f"ë™ì  ë¡œë“œ ëŒ€ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {module_path}")

    spec = importlib.util.spec_from_file_location("search_demo", module_path)
    if spec is None or spec.loader is None:
        raise ImportError("importlibì´ spec ë¡œë“œë¥¼ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ (spec/loader None).")

    search_demo = importlib.util.module_from_spec(spec)
    sys.modules["search_demo"] = search_demo
    spec.loader.exec_module(search_demo)
    return search_demo

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Retriever ìƒì„±(ìºì‹œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=True)
def get_retriever_cached():
    sd = load_search_demo_module()
    if not hasattr(sd, "get_retriever"):
        raise AttributeError("search_demo ëª¨ë“ˆì— get_retriever í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    retr = sd.get_retriever()
    return retr, sd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) íƒ€ì… í—¬í¼ + (index, model, items) ì •ê·œí™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _looks_like_faiss_index(obj: Any) -> bool:
    return hasattr(obj, "search") and callable(getattr(obj, "search"))

def _looks_like_st_model(obj: Any) -> bool:
    return hasattr(obj, "encode") and callable(getattr(obj, "encode"))

def _looks_like_items(obj: Any) -> bool:
    return isinstance(obj, list) and (len(obj) == 0 or isinstance(obj[0], dict))

def normalize_retriever_triplet(retr: Any) -> Tuple[Any, Any, List[Dict]]:
    if isinstance(retr, dict):
        idx = retr.get("index") or retr.get("faiss") or retr.get("faiss_index")
        mdl = retr.get("model") or retr.get("encoder") or retr.get("st_model")
        itm = retr.get("items") or retr.get("docs") or retr.get("metas")
        if idx is not None and mdl is not None and itm is not None:
            return idx, mdl, itm
    if hasattr(retr, "index") and hasattr(retr, "model") and hasattr(retr, "items"):
        return getattr(retr, "index"), getattr(retr, "model"), getattr(retr, "items")
    if isinstance(retr, (tuple, list)):
        idx = mdl = itm = None
        for x in retr:
            if idx is None and _looks_like_faiss_index(x):
                idx = x; continue
            if mdl is None and _looks_like_st_model(x):
                mdl = x; continue
            if itm is None and _looks_like_items(x):
                itm = x; continue
        if idx is not None and mdl is not None and itm is not None:
            return idx, mdl, itm
    raise TypeError("retrieverë¥¼ (index, model, items)ë¡œ ì •ê·œí™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) Dense ê²€ìƒ‰ (FAISS)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_query_faiss(index: Any, model: Any, items: List[Dict], query: str, top_k: int) -> List[Dict]:
    q_emb = model.encode([query], normalize_embeddings=True)
    if hasattr(q_emb, "astype"):
        q_emb = q_emb.astype("float32")
    else:
        q_emb = np.array(q_emb, dtype="float32")
    D, I = index.search(q_emb, top_k)
    scores = D[0].tolist()
    idxs = I[0].tolist()
    results: List[Dict] = []
    for rank, (i, sc) in enumerate(zip(idxs, scores), start=1):
        if i < 0 or i >= len(items):
            continue
        meta = items[i] or {}
        text = meta.get("text") or meta.get("sentence") or meta.get("content") or str(meta)
        results.append({"rank": rank, "text": text, "meta": meta, "score": float(sc)})
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) [ìë™ ì¹´í…Œê³ ë¦¬] ëª¨ë¸ êµ¬ì¶•
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _nz(s: str) -> str:
    return re.sub(r"\s+", "", str(s or "")).lower()

def _get_item_category(meta: Dict) -> str:
    return meta.get("category") or meta.get("Category") or meta.get("ì„¹ì…˜") or meta.get("section") or ""

def _top_keywords(texts: List[str], topn: int = 12) -> List[str]:
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        vect = TfidfVectorizer(
            analyzer="word",
            token_pattern=r"(?u)\b\w+\b",
            ngram_range=(1, 2),
            min_df=1,
            max_features=5000,
        )
        X = vect.fit_transform(texts)
        scores = np.asarray(X.sum(axis=0)).ravel()
        feats = np.array(vect.get_feature_names_out())
        order = np.argsort(scores)[::-1]
        return [feats[i] for i in order[:topn].tolist()]
    except Exception:
        from collections import Counter
        toks = []
        for t in texts:
            toks.extend([w for w in re.split(r"[,\s/;]+", t) if w])
        cnt = Counter(toks)
        return [w for w, _ in cnt.most_common(topn)]

@st.cache_resource(show_spinner=False)
def build_auto_categories(items: List[Dict], _model: Any) -> Dict[str, Dict[str, Any]]:
    """
    itemsì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡œí† íƒ€ì…/ë³„ì¹­ ìë™ ìƒì„±
    _model: SentenceTransformer (Streamlit ìºì‹œ í•´ì‹œ ì œì™¸ìš©)
    """
    cat_to_texts: Dict[str, List[str]] = {}
    for it in items:
        meta = it or {}
        cat = _get_item_category(meta)
        text = meta.get("text") or meta.get("sentence") or meta.get("content") or ""
        if not text or not cat:
            continue
        cat_to_texts.setdefault(cat, []).append(str(text))

    auto: Dict[str, Dict[str, Any]] = {}
    if not cat_to_texts:
        return auto

    for cat, texts in cat_to_texts.items():
        sample = texts[:200]
        emb = _model.encode(sample, normalize_embeddings=True)
        if isinstance(emb, list):
            emb = np.array(emb, dtype="float32")
        proto = emb.mean(axis=0)

        aliases = _top_keywords(sample, topn=12)
        alias_emb = _model.encode(aliases, normalize_embeddings=True)
        alias_emb = np.array(alias_emb, dtype="float32")

        auto[cat] = {
            "prototype": proto.astype("float32"),
            "aliases": aliases,
            "alias_emb": alias_emb,
        }
    return auto

def _cos(a: np.ndarray, b: np.ndarray) -> float:
    return float(np.dot(a, b))

def infer_category_auto(query: str, model: Any, AUTO_CATS: Dict[str, Dict[str, Any]],
                        proto_w: float = 1.0, alias_w: float = 0.8,
                        th: float = 0.35) -> str | None:
    if not AUTO_CATS:
        return None
    q_emb = model.encode([query], normalize_embeddings=True)
    q = np.array(q_emb[0], dtype="float32")
    best_cat, best_score = None, -1.0
    for cat, info in AUTO_CATS.items():
        proto = info["prototype"]
        alias_emb = info["alias_emb"]
        s_proto = _cos(q, proto)
        s_alias = float(np.max(alias_emb @ q)) if alias_emb.size else 0.0
        s = proto_w * s_proto + alias_w * s_alias
        if s > best_score:
            best_score, best_cat = s, cat
    return best_cat if best_score >= th else None

# â”€â”€ í•µì‹¬ í‚¤ ê¸°ë°˜ ë¹„êµ + ì•ˆì „ alias ë§¤ì¹­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _cat_key(cat: str) -> str:
    s = _nz(cat)
    if "ìš´ë™ì „" in s: return "ì „"
    if "ìš´ë™ì¤‘" in s: return "ì¤‘"
    if "ìš´ë™í›„" in s: return "í›„"
    if any(k in s for k in ["ê·¼ë ¥", "ì €í•­", "ì›¨ì´íŠ¸", "strength", "resistance"]): return "ê·¼ë ¥"
    if any(k in s for k in ["ê· í˜•", "ë°¸ëŸ°ìŠ¤", "balance", "stability"]):           return "ê· í˜•"
    if any(k in s for k in ["ìŠ¤íŠ¸ë ˆì¹­", "ìœ ì—°", "rom", "flex", "flexibility"]):     return "ìŠ¤íŠ¸ë ˆì¹­"
    return s

STOP_ALIASES = {"ìš´ë™", "ì£¼ì˜ì‚¬í•­", "exercise", "note", "ì£¼ì˜"}

def category_matches_auto(item_cat: str, target_cat: str,
                          AUTO_CATS: Dict[str, Dict[str, Any]]) -> bool:
    if not item_cat or not target_cat:
        return False
    # 1) í•µì‹¬ í‚¤ ì¼ì¹˜ ìš°ì„ 
    if _cat_key(item_cat) == _cat_key(target_cat):
        return True
    # 2) ì•ˆì „ alias ë¶€ë¶„ì¼ì¹˜(3ê¸€ì ì´ìƒ + ê¸ˆì§€ì–´ ì œì™¸)
    for alias in AUTO_CATS.get(target_cat, {}).get("aliases", []):
        a = _nz(alias)
        if len(a) >= 3 and a not in STOP_ALIASES and a in _nz(item_cat):
            return True
    return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ì¹´í…Œê³ ë¦¬ ì¸ì§€í˜• ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rerank_by_category_auto(results: List[Dict], cat_hint: str | None,
                            AUTO_CATS: Dict[str, Dict[str, Any]]) -> List[Dict]:
    if not cat_hint:
        return results
    same, other = [], []
    for r in results:
        meta = r.get("meta", {}) or {}
        item_cat = _get_item_category(meta)
        (same if category_matches_auto(item_cat, cat_hint, AUTO_CATS) else other).append(r)
    return same + other

def count_matches_auto(results: List[Dict], cat_hint: str | None,
                       AUTO_CATS: Dict[str, Dict[str, Any]]) -> int:
    if not cat_hint:
        return 0
    return sum(1 for r in results
               if category_matches_auto(_get_item_category(r.get("meta", {}) or {}), cat_hint, AUTO_CATS))

def run_category_aware_search(sd: Any, retr: Any, query: str, top_k: int,
                              AUTO_CATS: Dict[str, Dict[str, Any]]) -> List[Dict]:
    index = model = items = None
    if hasattr(sd, "search"):
        try:
            results = sd.search(retr, query, top_k=top_k)
        except TypeError:
            results = sd.search(retr, query)
        try:
            index, model, items = normalize_retriever_triplet(retr)
        except Exception:
            pass
    elif callable(retr):
        try:
            results = retr(query, top_k=top_k)
        except TypeError:
            results = retr(query)
        try:
            index, model, items = normalize_retriever_triplet(retr)
        except Exception:
            pass
    else:
        index, model, items = normalize_retriever_triplet(retr)
        results = run_query_faiss(index, model, items, query, top_k)

    cat_hint = infer_category_auto(query, model, AUTO_CATS)

    results = sorted(results, key=lambda x: x.get("score", 0.0), reverse=True)
    results = rerank_by_category_auto(results, cat_hint, AUTO_CATS)

    if cat_hint and count_matches_auto(results, cat_hint, AUTO_CATS) == 0 and index is not None:
        over_k = max(top_k * 10, 30)
        big = run_query_faiss(index, model, items, query, over_k)
        big = sorted(big, key=lambda x: x.get("score", 0.0), reverse=True)
        big = rerank_by_category_auto(big, cat_hint, AUTO_CATS)
        if count_matches_auto(big, cat_hint, AUTO_CATS) > 0:
            results = big[:top_k]

    if cat_hint and count_matches_auto(results, cat_hint, AUTO_CATS) == 0 and index is not None:
        aliases = " ".join(AUTO_CATS.get(cat_hint, {}).get("aliases", [])[:8])
        q_exp = f"{query} {aliases}"
        big = run_query_faiss(index, model, items, q_exp, max(top_k * 10, 30))
        big = sorted(big, key=lambda x: x.get("score", 0.0), reverse=True)
        big = rerank_by_category_auto(big, cat_hint, AUTO_CATS)
        if count_matches_auto(big, cat_hint, AUTO_CATS) > 0:
            results = big[:top_k]

    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) ìŠ¤ì½”ì–´ ë³´ì • ìœ í‹¸(ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_korean(s: str) -> str:
    return re.sub(r"\s+", "", str(s)).lower()

def keyword_overlap_ratio(query: str, keywords) -> float:
    if not keywords:
        return 0.0
    if isinstance(keywords, str):
        kws = [k.strip() for k in re.split(r"[,\s/;]+", keywords) if k.strip()]
    else:
        kws = [str(k).strip() for k in keywords if str(k).strip()]
    if not kws:
        return 0.0
    q_tokens = [t for t in re.split(r"[,\s/;]+", query) if t]
    inter = len(set(map(normalize_korean, q_tokens)) & set(map(normalize_korean, kws)))
    return inter / max(len(set(kws)), 1)

def boosted_sort(results: List[Dict], query: str, cat_hint: str | None,
                 w_cat: float = 0.08, w_kw: float = 0.05,
                 AUTO_CATS: Dict[str, Dict[str, Any]] | None = None) -> List[Dict]:
    AUTO_CATS = AUTO_CATS or {}
    ranked = []
    for r in results:
        base = float(r.get("score", 0.0))
        meta = r.get("meta", {}) or {}
        cat = _get_item_category(meta)
        kw = meta.get("keywords") or meta.get("Keywords")
        cat_bonus = (w_cat if (cat_hint and category_matches_auto(cat, cat_hint, AUTO_CATS)) else 0.0)
        kw_bonus = w_kw * keyword_overlap_ratio(query, kw)
        new_score = base + cat_bonus + kw_bonus
        r2 = dict(r)
        r2["adj_score"] = new_score
        r2["cat_bonus"] = cat_bonus
        r2["kw_bonus"] = kw_bonus
        ranked.append(r2)
    ranked.sort(key=lambda x: x.get("adj_score", 0.0), reverse=True)
    return ranked

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) UI ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def score_badge(score: float) -> str:
    if score >= 0.9:
        return "ğŸŸ¢"
    if score >= 0.8:
        return "ğŸŸ¡"
    return "ğŸŸ "

def extract_category(meta: Dict) -> str:
    return _get_item_category(meta)

def extract_tag(meta: Dict, key: str) -> str:
    return meta.get(key) or meta.get(key.lower()) or meta.get(key.capitalize()) or ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) Streamlit App
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.set_page_config(page_title="RAG App Demo", page_icon="ğŸ”", layout="wide")
    st.title("ğŸ” RAG ê²€ìƒ‰ ë°ëª¨")

    with st.sidebar:
        st.header("ê²€ìƒ‰ ì˜µì…˜")
        query = st.text_input("ì§ˆì˜(Query)", value="ìš´ë™ í›„ ì£¼ì˜ì‚¬í•­ì€?")
        top_k = st.slider("Top-K", 1, 10, 3)
        threshold = st.slider("Score ìµœì†Œê°’(í•„í„°)", 0.0, 1.0, 0.80, 0.01)
        st.markdown("### ê°€ì¤‘ì¹˜")
        w_cat = st.slider("ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜ (w_cat)", 0.0, 0.20, 0.08, 0.01)
        w_kw  = st.slider("í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ (w_kw)",  0.0, 0.20, 0.05, 0.01)
        strict = st.checkbox("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ í‘œì‹œ(ê°•ì œ í•„í„°)", value=False)

    try:
        retr, sd = get_retriever_cached()
        index, model, items = normalize_retriever_triplet(retr)
        AUTO_CATS = build_auto_categories(items, model)  # _model ì¸ìëª…ìœ¼ë¡œ ìºì‹œ í•´ì‹œ íšŒí”¼
    except Exception as e:
        st.error(f"ë¦¬íŠ¸ë¦¬ë²„/ì¹´í…Œê³ ë¦¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", use_container_width=True):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            try:
                results = run_category_aware_search(sd, retr, query, top_k, AUTO_CATS)
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                st.stop()

        if not results:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        cat_hint = infer_category_auto(query, model, AUTO_CATS)
        if cat_hint:
            st.caption(f"ğŸ” ìë™ ì¶”ë¡  ì¹´í…Œê³ ë¦¬: **{cat_hint}**")

        if strict and cat_hint:
            results = [
                r for r in results
                if category_matches_auto(extract_category(r.get("meta", {}) or {}), cat_hint, AUTO_CATS)
            ]

        results = [r for r in results if float(r.get("score", 0.0)) >= threshold]
        results = boosted_sort(results, query, cat_hint, w_cat=w_cat, w_kw=w_kw, AUTO_CATS=AUTO_CATS)

        st.subheader("ê²€ìƒ‰ ê²°ê³¼")
        for r in results:
            text = r.get("text", "").strip()
            meta = r.get("meta", {}) or {}
            base = float(r.get("score", 0.0))
            adj  = float(r.get("adj_score", base))
            cat = extract_category(meta)
            sev = extract_tag(meta, "Severity")
            intent = extract_tag(meta, "Intent")
            keywords = meta.get("keywords") or meta.get("Keywords") or []
            cb = r.get("cat_bonus", 0.0); kb = r.get("kw_bonus", 0.0)

            with st.container(border=True):
                cols = st.columns([6, 1])
                with cols[0]:
                    st.markdown(f"**[{cat}]** {text}" if cat else text)
                    if sev or intent or keywords:
                        smalls = []
                        if sev:    smalls.append(f"**Severity:** {sev}")
                        if intent: smalls.append(f"**Intent:** {intent}")
                        if keywords:
                            kw = ", ".join(map(str, keywords)) if isinstance(keywords, list) else str(keywords)
                            smalls.append(f"**Keywords:** {kw}")
                        st.caption(" Â· ".join(smalls))
                with cols[1]:
                    st.metric(label="Score", value=f"{score_badge(base)} {base:.3f}",
                              delta=f"adj {adj:.3f}")
                    st.caption(f"cat+{cb:.3f} / kw+{kb:.3f}")

        st.subheader("ì„ì‹œ ë‹µì•ˆ (Draft)")
        draft_answer = " ".join([r.get("text", "").strip() for r in results[:2] if r.get("text")])
        if draft_answer:
            st.write(draft_answer)
        else:
            st.info("ìƒìœ„ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•  ì„ì‹œ ë‹µì•ˆì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
