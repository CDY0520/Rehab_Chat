"""
íŒŒì¼: rag/04_answer_demo.py
ëª©ì : ì§ˆì˜ â†’ FAISS ê²€ìƒ‰ â†’ ê·œì¹™ ê¸°ë°˜(í…œí”Œë¦¿) ë‹µë³€ ìƒì„± (+ ì¶œì²˜ í‘œê¸°, ì•ˆì „ ê²½ê³ )
ì˜µì…˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ LLM ìš”ì•½ ëª¨ë“œë¡œë„ ë‹µë³€ ê°€ëŠ¥

ìš”êµ¬:
  - sentence-transformers, faiss-cpu (ì´ë¯¸ ì´ì „ ë‹¨ê³„ì—ì„œ ì„¤ì¹˜)
  - (ì„ íƒ) openai==1.*  (í‚¤ê°€ ìˆì„ ë•Œë§Œ)
ì‹¤í–‰:
  python rag/04_answer_demo.py
"""

from pathlib import Path
import os
import pickle
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
import faiss

try:
    from openai import OpenAI
    HAS_OPENAI = True
except Exception:
    HAS_OPENAI = False

ROOT = Path(__file__).resolve().parents[1]
VEC_DIR = ROOT / "data" / "vectorstore"
FAISS_INDEX_PATH = VEC_DIR / "faiss.index"
META_PATH        = VEC_DIR / "meta.pkl"

# -----------------------------
# ê³µí†µ ìœ í‹¸
# -----------------------------
def load_index_meta_model():
    index = faiss.read_index(str(FAISS_INDEX_PATH))
    with open(META_PATH, "rb") as f:
        meta = pickle.load(f)
    model = SentenceTransformer(meta["model_name"])
    return index, meta, model

def search(q: str, top_k: int = 5,
           category: str | None = None,
           severity: str | None = None,
           intent: str | None = None) -> List[Dict[str, Any]]:
    """03_search_demo.pyì™€ ë™ì¼í•œ ë¡œì§(í•„í„° + ê²€ìƒ‰)"""
    index, meta, model = load_index_meta_model()
    candidates = list(range(len(meta["records"])))
    if category:
        candidates = [i for i in candidates if meta["records"][i].get("category") == category]
    if severity:
        candidates = [i for i in candidates if meta["records"][i].get("severity") == severity]
    if intent:
        candidates = [i for i in candidates if meta["records"][i].get("intent") == intent]
    if not candidates:
        return []

    q_emb = model.encode([q], normalize_embeddings=True).astype("float32")
    D, I = index.search(q_emb, k=min(top_k*10, len(meta["texts"])))

    hits = []
    seen_text = set()
    for dist, idx in zip(D[0], I[0]):
        if idx not in candidates:
            continue
        rec = meta["records"][idx]
        text = rec["canonical_ko"].strip()
        # ì¤‘ë³µ ë¬¸ì¥ ì œê±°
        key = " ".join(text.split())
        if key in seen_text:
            continue
        seen_text.add(key)
        hits.append({
            "score": float(dist),
            "id": rec["id"],
            "text": text,
            "category": rec.get("category"),
            "severity": rec.get("severity"),
            "intent": rec.get("intent"),
            "source_title": rec.get("source_title"),
            "source_page": rec.get("source_page"),
            "source_orig_page": rec.get("source_orig_page"),
        })
        if len(hits) >= top_k:
            break
    return hits

# -----------------------------
# ê·œì¹™ ê¸°ë°˜(í…œí”Œë¦¿) ë‹µë³€ ìƒì„±
# -----------------------------
def prioritize(results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """High > Medium > Low ìš°ì„ , ê·¸ ë‹¤ìŒ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ"""
    sev_rank = {"High": 0, "Medium": 1, "Low": 2}
    return sorted(results, key=lambda r: (sev_rank.get(r.get("severity","Low"), 3), -r["score"]))

def format_sources(results: List[Dict[str, Any]]) -> str:
    lines = []
    for r in results:
        page = r.get("source_orig_page") or r.get("source_page")
        lines.append(f"- {r['source_title']} (p.{page}, {r['id']})")
    # ì¤‘ë³µ ì œê±°
    uniq = []
    seen = set()
    for L in lines:
        if L not in seen:
            seen.add(L)
            uniq.append(L)
    return "\n".join(uniq)

def rule_based_answer(question: str, results: List[Dict[str, Any]]) -> str:
    if not results:
        return "ê´€ë ¨ ê·¼ê±°ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë°”ê¿”ë³´ê±°ë‚˜ ë‹¤ë¥¸ í‘œí˜„ì„ ì‹œë„í•´ ì£¼ì„¸ìš”."

    ordered = prioritize(results)
    high_exists = any(r.get("severity") == "High" for r in ordered)

    bullets = []
    for r in ordered:
        tone = r.get("intent")
        sev = r.get("severity")
        prefix = "â€¢"
        if sev == "High":
            prefix = "ğŸš¨"
        elif sev == "Medium":
            prefix = "âš ï¸"
        elif tone == "ê¶Œì¥":
            prefix = "âœ…"

        bullets.append(f"{prefix} {r['text']}")

    src = format_sources(ordered)

    header = "ì•„ë˜ ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬í–ˆì–´ìš”.\n"
    if high_exists:
        header = "ğŸš¨ ì•ˆì „ ìš°ì„  ì•ˆë‚´\nìœ„í—˜ ì‹ í˜¸ê°€ í¬í•¨ë˜ì–´ ìˆì–´ **ë¨¼ì € ì•ˆì „ ì§€ì¹¨**ì„ ë”°ë¥´ì„¸ìš”.\n\n"

    answer = (
        f"{header}"
        f"Q. {question}\n\n"
        + "\n".join(bullets)
        + "\n\n"
        + "ì¶œì²˜:\n"
        + src
    )
    return answer

# -----------------------------
# (ì„ íƒ) LLM ìš”ì•½ ë‹µë³€
# -----------------------------
def llm_answer(question: str, results: List[Dict[str, Any]]) -> str:
    """OPENAI_API_KEYê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©. ê·œì¹™ê¸°ë°˜ ëŒ€ë¹„ ìì—°ìŠ¤ëŸ¬ì›€ ê°•í™”."""
    if not results or not HAS_OPENAI or not os.getenv("OPENAI_API_KEY"):
        return rule_based_answer(question, results)

    client = OpenAI()
    ctx = "\n".join([f"- ({r['severity']}/{r['intent']}) {r['text']} [ì¶œì²˜: {r['source_title']} p.{r.get('source_orig_page') or r.get('source_page')}]"
                     for r in prioritize(results)])

    prompt = f"""ë„ˆëŠ” ë‡Œì¡¸ì¤‘ ì¬í™œ ìš´ë™ ì•ˆì „ ê°€ì´ë“œ ì±—ë´‡ì´ì•¼.
ì‚¬ìš©ì ì§ˆë¬¸: {question}
ë‹¤ìŒ ê·¼ê±°ë¥¼ ì•ˆì „ë„ ìˆœìœ¼ë¡œ ìš”ì•½í•´, ê¸ˆì§€/ì£¼ì˜/ê¶Œì¥ ìš°ì„ ìˆœìœ„ë¡œ ì•ˆë‚´í•˜ê³  ë§ˆì§€ë§‰ì— ì¶œì²˜ë¥¼ ë‚˜ì—´í•´.
ê·¼ê±°:
{ctx}
ì¶œë ¥ í˜•ì‹:
- í•µì‹¬ ì§€ì¹¨ 3~6ì¤„ (ê¸ˆì§€/ì£¼ì˜ ë¨¼ì €, ê¶Œì¥ì€ ë§ˆì§€ë§‰)
- 'ì¶œì²˜:' ì•„ë˜ì— ë¬¸ì„œëª…ê³¼ ì›ë³¸ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ í‘œê¸°
"""
    chat = client.chat.completions.create(
        model="gpt-4o-mini",  # ë˜ëŠ” ê°€ëŠ¥í•œ ì±„íŒ… ëª¨ë¸
        messages=[{"role":"user","content":prompt}],
        temperature=0.2,
    )
    return chat.choices[0].message.content.strip()

# -----------------------------
# ë°ëª¨ ì‹¤í–‰
# -----------------------------
if __name__ == "__main__":
    queries = [
        "ì‹ì‚¬ ì§í›„ ìš´ë™í•´ë„ ë¼?",
        "ìš´ë™ ì „ í˜ˆì•• í™•ì¸í•´ì•¼ í•´?",
        "ë‘í†µì´ ìˆìœ¼ë©´ ìš´ë™ ê°€ëŠ¥í•´?",
        "ê· í˜•ì´ ë¶ˆì•ˆì •í•  ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•´?"
    ]
    use_llm = bool(os.getenv("OPENAI_API_KEY")) and HAS_OPENAI

    for q in queries:
        results = search(q, top_k=5)
        ans = llm_answer(q, results) if use_llm else rule_based_answer(q, results)
        print("="*80)
        print(ans)
        print("="*80)
